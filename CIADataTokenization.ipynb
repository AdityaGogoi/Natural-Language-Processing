{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Dataset\n",
    "#### Our dataset contains excerpts from CIA memos that detail covert activities.\n",
    "#### It includes the year the statement was made, an an excerpt from the memo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step will be to import the data from the CSV file.\n",
    "#### The file uses utf-8 encoding, and we will use this to decode the data into our data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n",
      "The FBI information included that al-Mairi's brother \"traveled to Afghanistan in 1997-1998 to train in Bin - Ladencamps.\"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "f = open(\"sentences_cia.csv\",'r',encoding=\"utf-8\")\n",
    "csvreader = csv.reader(f)\n",
    "sentences_cia = list(csvreader)\n",
    "\n",
    "# Printing the Year and Excerpt column\n",
    "print(sentences_cia[1][0])\n",
    "print(sentences_cia[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Dataframe\n",
    "#### Will store the list of lists to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>The FBI information included that al-Mairi's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>The FBI information included that al-Mairi's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>For example, on October 12, 2004, another CIA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>On October 16, 2001, an email from a CTC offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>For example, on October 12, 2004, another CIA ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                          statement\n",
       "0  1997  The FBI information included that al-Mairi's b...\n",
       "1  1997  The FBI information included that al-Mairi's b...\n",
       "2  1997  For example, on October 12, 2004, another CIA ...\n",
       "3  1997  On October 16, 2001, an email from a CTC offic...\n",
       "4  1997  For example, on October 12, 2004, another CIA ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences_cia_df = pd.DataFrame(sentences_cia[1:],columns=sentences_cia[0])\n",
    "sentences_cia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up sentences\n",
    "#### We will now remove extraneous symbols from the sentences column. We only need letters, digits and spaces.\n",
    "#### We will do this using the ord() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Integer code of all characters we want to to keep.\n",
    "good_characters = [48,49,50,51,52,53,54,55,56,65,66,67,68,69,70,71,72,73,74,75,76,\n",
    "                   77,78,79,80,81,82,83,84,85,86,87,88,89,90,97,98,99,100,101,102,103,\n",
    "                   104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,\n",
    "                   120,121,122,32]\n",
    "\n",
    "def clean(row):\n",
    "    statement = row['statement']\n",
    "    clean_statement_list = [s for s in statement if ord(s) in good_characters]\n",
    "    clean_statement = \"\".join(clean_statement_list)\n",
    "    return clean_statement\n",
    "\n",
    "sentences_cia_df['cleaned_statement'] = sentences_cia_df.apply(clean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>statement</th>\n",
       "      <th>cleaned_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>The FBI information included that al-Mairi's b...</td>\n",
       "      <td>The FBI information included that alMairis bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>The FBI information included that al-Mairi's b...</td>\n",
       "      <td>The FBI information included that alMairis bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>For example, on October 12, 2004, another CIA ...</td>\n",
       "      <td>For example on October 12 2004 another CIA det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>On October 16, 2001, an email from a CTC offic...</td>\n",
       "      <td>On October 16 2001 an email from a CTC officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>For example, on October 12, 2004, another CIA ...</td>\n",
       "      <td>For example on October 12 2004 another CIA det...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                          statement  \\\n",
       "0  1997  The FBI information included that al-Mairi's b...   \n",
       "1  1997  The FBI information included that al-Mairi's b...   \n",
       "2  1997  For example, on October 12, 2004, another CIA ...   \n",
       "3  1997  On October 16, 2001, an email from a CTC offic...   \n",
       "4  1997  For example, on October 12, 2004, another CIA ...   \n",
       "\n",
       "                                   cleaned_statement  \n",
       "0  The FBI information included that alMairis bro...  \n",
       "1  The FBI information included that alMairis bro...  \n",
       "2  For example on October 12 2004 another CIA det...  \n",
       "3  On October 16 2001 an email from a CTC officer...  \n",
       "4  For example on October 12 2004 another CIA det...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_cia_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Statements\n",
    "#### We will now combine statements and convert them into tokens.\n",
    "#### Eventually, we will count up how many times each token occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'FBI', 'information', 'included', 'that']\n"
     ]
    }
   ],
   "source": [
    "combined_statements = \" \".join(sentences_cia_df[\"cleaned_statement\"])\n",
    "statement_tokens = combined_statements.split(\" \")\n",
    "print(statement_tokens[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the Tokens\n",
    "#### Some of the most fequently occuring words are 'stopwords'like a, an, the, etc.\n",
    "#### They do not add much information to our analysis.\n",
    "#### A simple way to remove stopwords is to filter out all the words that have less than 4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['information', 'included', 'alMairis', 'brother', 'traveled']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens=[]\n",
    "for token in statement_tokens:\n",
    "    if len(token) > 4:\n",
    "        filtered_tokens.append(token)\n",
    "\n",
    "print(filtered_tokens[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the tokens\n",
    "#### After filtering, we can count how many times a token occurs.\n",
    "#### We can use 'counter' object from 'collections' library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "filtered_token_counts = Counter(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Tokens\n",
    "#### With the help of counter, we can get the most common tokens within the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('REDACTED', 1746), ('General', 1509), ('interrogation', 1453), ('Interrogation', 1440), ('techniques', 1198)]\n"
     ]
    }
   ],
   "source": [
    "common_tokens = filtered_token_counts.most_common(5)\n",
    "print(common_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common Tokens by Year\n",
    "#### We will now find the most common tokens by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ahmad', 9), ('terrorist', 9), ('Afghanistan', 6), ('training', 6), ('Padilla', 6)]\n",
      "[('interrogation', 298), ('Zubaydah', 267), ('August', 261), ('REDACTED', 251), ('techniques', 231)]\n",
      "[('Response', 196), ('states', 111), ('information', 101), ('reporting', 59), ('Committee', 55)]\n",
      "[('UNCLASSIFIED', 32), ('Committee', 29), ('REDACTED', 22), ('SECRET', 19), ('162014Z', 18)]\n"
     ]
    }
   ],
   "source": [
    "def clean(year):\n",
    "    df = sentences_cia_df[sentences_cia_df['year']==year]\n",
    "    combined_statements = \" \".join(df[\"cleaned_statement\"])\n",
    "    statement_tokens = combined_statements.split(\" \")\n",
    "    filtered_tokens=[]\n",
    "    for token in statement_tokens:\n",
    "        if len(token) > 4:\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_token_counts = Counter(filtered_tokens)\n",
    "    common_tokens = filtered_token_counts.most_common(5)\n",
    "    return common_tokens\n",
    "\n",
    "common_2000 = clean(\"2000\")\n",
    "common_2002 = clean(\"2002\")\n",
    "common_2013 = clean(\"2013\")\n",
    "common_2014 = clean(\"2014\")\n",
    "print(common_2000)\n",
    "print(common_2002)\n",
    "print(common_2013)\n",
    "print(common_2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "#### Using the above simple techniques, we can easily tokenize and get count after cleaning the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
